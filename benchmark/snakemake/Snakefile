
import pandas as pd
from pathlib import Path
from snakemake.utils import min_version

min_version("8.0.0")
conda: "../environments/snake_env.yaml"
configfile: "../configuration/config.yaml"
TEMPDIR = Path(config["TEMPDIR"])

def increment_memory(base_memory):
    def mem(wildcards, attempt):
        return base_memory * (2 ** (attempt - 1))
    return mem

rule all:
    input:
        # AUGUR
        expand("../results/augur_{n_sample}_{implementation}.csv", 
               n_sample=[0, 1000, 5000, 10000, 50000, 100000, 500000, 1000000, 3000000], 
               implementation=["py", "r"]),
        # MILO
        expand("../results/milo_{n_sample}_{ext}",
               n_sample=[0, 1000, 5000, 10000, 50000, 100000, 500000, 1000000, 3000000],
               ext=["py.h5mu", "r.csv"]),

## AUGUR
rule augur_pertpy:
    output:
        "../results/augur_{n_sample}_py.csv",
    conda: "../environments/pertpy_env.yaml"
    benchmark:
        repeat("benchmarks/augur.{n_sample}.pertpy.benchmark.tsv", 3)
    threads: 16
    retries: 3
    resources:
        mem_mb=increment_memory(64000),
        time=60
    script: "../augur/augur.py"

rule augur_original:
    output:
        out_sim = "../results/augur_{n_sample}_r.csv",
    conda: "augur_env"  # "../environments/augur_env.yaml"
    benchmark:
        repeat("benchmarks/augur.{n_sample}.original.benchmark.tsv", 3)
    threads: 16
    retries: 3
    resources:
        mem_mb=increment_memory(64000),
        time=60
    script: "../augur/augur.R"

## MILO
rule milo_prepare_data:
    output:
        h5ad=TEMPDIR / "milo_data_{n_sample}.h5ad",
        obs=TEMPDIR / "milo_obs_{n_sample}.csv",
        obsm_scvi=TEMPDIR / "milo_obsm_scvi_{n_sample}.csv",
        obsm_umap=TEMPDIR / "milo_obsm_umap_{n_sample}.csv"
    retries: 3
    resources:
        mem_mb=increment_memory(64000),
        time=60
    conda: "../environments/pertpy_env.yaml"
    script: "../milo/milo_prepare.py"

rule milo_py:
    input:
        h5ad=TEMPDIR / "milo_data_{n_sample}.h5ad",
    output:
        milo_res="../results/milo_{n_sample}_py.h5mu"
    conda: "../milo/milo_env.yaml"
    benchmark:
        repeat("benchmarks/milo.{n_sample}.pertpy.benchmark.tsv", 3)
    threads: 16
    retries: 3
    resources:
        mem_mb=increment_memory(64000),
        time=60
    script: "../milo/milo.py"

rule milo_r:
    input:
        obs=TEMPDIR / "milo_obs_{n_sample}.csv",
        obsm_scvi=TEMPDIR / "milo_obsm_scvi_{n_sample}.csv",
        obsm_umap=TEMPDIR / "milo_obsm_umap_{n_sample}.csv"
    output:
        milo_res="../results/milo_{n_sample}_r.csv",
        milo_res_graph="../results/milo_{n_sample}_nhoods.mtx"
    conda: "milo_env" # "../environments/milo_env.yaml"
    benchmark:
        repeat("benchmarks/milo.{n_sample}.original.benchmark.tsv", 3)
    threads: 16
    retries: 3
    resources:
        mem_mb=increment_memory(64000),
        time=60
    script: "../milo/milo.R"
    

## MIXSCAPE
# rule mixscape:
#     output:
#         "../results/mixscape.csv"
#     log:
#         notebook="logs/notebooks/processed_mixscape.ipynb"
#     conda: "../environments/mixscape_env.yaml"
#     notebook: "../scripts/mixscape_compare.ipynb"

## SCCODA
# rule sccoda:
#     output:
#         "../results/sccoda.csv"
#     log:
#         notebook="logs/notebooks/processed_sccoda.ipynb"
#     conda: "../environments/sccoda_env.yaml"
#     notebook: "../scripts/sccoda_compare.ipynb"
